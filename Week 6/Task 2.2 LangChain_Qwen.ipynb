{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55606469",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import getpass\n",
    "\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Access groq_key\n",
    "groq_key = os.getenv(\"GROQ_API_KEY\")\n",
    "if \"GROQ_API_KEY\" not in os.environ:\n",
    "    os.environ[\"GROQ_API_KEY\"] = getpass.getpass(groq_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36bac7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Imports\n",
    "import gradio as gr\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import arabic_reshaper\n",
    "from bidi.algorithm import get_display\n",
    "from surya.recognition import RecognitionPredictor\n",
    "from surya.detection import DetectionPredictor\n",
    "from surya.layout import LayoutPredictor\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# 2. Initialize predictors\n",
    "det_predictor = DetectionPredictor()\n",
    "rec_predictor = RecognitionPredictor()\n",
    "layout_predictor = LayoutPredictor()\n",
    "\n",
    "# 3. Initialize Groq LLaMA-3\n",
    "llm = ChatGroq(\n",
    "    model=\"llama-3.1-8b-instant\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed684520",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import json\n",
    "\n",
    "# Map options to file paths\n",
    "document_options = {\n",
    "    \"Passport\": {\"image\": \"./Qwen/Output/Passport/Passport.png\", \"json\": \"./Qwen/Output/Passport/Result 2/Passport.json\"},\n",
    "    \"ID\": {\"image\": \"./Qwen/Output/UAE_ID/UAE_ID.jpg\", \"json\": \"./Qwen/Output/UAE_ID/UAE_ID.json\"},\n",
    "    \"Bill\": {\"image\": \"./Qwen/Output/Bill/bill1.png\", \"json\": \"./Qwen/Output/Bill/Bill.json\"},\n",
    "    \"Bank Statement\": {\"image\": \"./Qwen/Output/Bank Statement/BankStatement2.jpeg\", \"json\": \"./Qwen/Output/Bank Statement/BankStatement2.json\"}\n",
    "}\n",
    "\n",
    "# Load selected document data\n",
    "def load_document(doc_type):\n",
    "    paths = document_options.get(doc_type, {})\n",
    "    image = Image.open(paths[\"image\"]) if \"image\" in paths else None\n",
    "    json_data = {}\n",
    "\n",
    "    if \"json\" in paths:\n",
    "        with open(paths[\"json\"], \"r\", encoding=\"utf-8\") as f:\n",
    "            json_data = json.load(f)\n",
    "\n",
    "    return image, json.dumps(json_data, indent=2, ensure_ascii=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fd525738",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7863\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7863/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# QA function using the selected document's JSON\n",
    "def qa_on_json(question, json_content):\n",
    "    prompt_template = f\"\"\"\n",
    "You are a document QA assistant.\n",
    "\n",
    "Here is the extracted JSON content from the uploaded document:\n",
    "\n",
    "{json_content}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Answer:\n",
    "\"\"\"\n",
    "    response = llm.invoke(prompt_template)\n",
    "    return response.content\n",
    "\n",
    "# Gradio Interface\n",
    "with gr.Blocks() as iface:\n",
    "    gr.Markdown(\"# üìÑ Document JSON QA Demo\")\n",
    "    gr.Markdown(\"Select a document type to view its image and JSON, then ask questions using LLaMA-3 via Groq.\")\n",
    "\n",
    "    doc_choice = gr.Dropdown(\n",
    "        choices=list(document_options.keys()),\n",
    "        label=\"Choose Document Type\",\n",
    "        value=\"Passport\"\n",
    "    )\n",
    "\n",
    "    image_display = gr.Image(label=\"Document Image\")\n",
    "    json_display = gr.Textbox(label=\"Extracted JSON\", lines=20)\n",
    "    \n",
    "    # Load selected document\n",
    "    doc_choice.change(\n",
    "        load_document,\n",
    "        inputs=doc_choice,\n",
    "        outputs=[image_display, json_display]\n",
    "    )\n",
    "\n",
    "    gr.Markdown(\"### ‚ùì Ask a Question about this document\")\n",
    "    question_input = gr.Textbox(label=\"Your Question\")\n",
    "    answer_output = gr.Textbox(label=\"LLaMA-3 Answer\")\n",
    "\n",
    "    question_input.submit(qa_on_json, inputs=[question_input, json_display], outputs=answer_output)\n",
    "\n",
    "iface.launch()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
